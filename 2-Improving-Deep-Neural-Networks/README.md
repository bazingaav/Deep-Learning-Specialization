# Course 2 : Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimization<br>

* Understood the importance and need of dev set.
* Implemented and understood reguarization techniques like:
  * L2 Regularization
  * Drop Out Regularization
  * Data Augmentation
  * Early Stopping
  * Normalization
  * Vanishing/Exploding Gradients
* Implemented various Optimization algorithms like:
  * Mini-batch Gradient Descent
  * Gradient Descent with Momentum
  * RMS Prop
  * Adam (RMS Prop + GD with Momentum)
* Understood the importance of hyper-parameter tuning 
* Understood the concept of Batch Normalization and Soft-max Regression
  

### Certificate<br><hr>
![Certificate](https://github.com/bazingaav/Deep-Learning-Specialization/blob/master/2-Improving-Deep-Neural-Networks/Certificate-Improving-Deep-Neural-Networks.jpg)
